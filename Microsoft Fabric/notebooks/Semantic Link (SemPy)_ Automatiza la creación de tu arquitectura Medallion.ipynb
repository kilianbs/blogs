{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f836878-fe1c-4255-b5e2-2acd6c5aa05f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4392be8-1e9d-449d-aaca-c14c4ab0c1f1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-06T13:53:25.4777232Z",
       "execution_start_time": "2025-04-06T13:53:21.9211786Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "1bfae7e0-15ec-459e-b956-4cf7e209d838",
       "queued_time": "2025-04-06T13:53:15.9920988Z",
       "session_id": "53be198c-a29e-4e26-a4ef-280d4d527fc2",
       "session_start_time": "2025-04-06T13:53:15.9931564Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, 53be198c-a29e-4e26-a4ef-280d4d527fc2, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sempy.fabric as fabric\n",
    "from sempy.fabric.exceptions import FabricHTTPException\n",
    "import msal\n",
    "import requests\n",
    "client = fabric.FabricRestClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde95f4c-fe08-4c0e-aa2c-3b6d824dfe77",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Listar capacidades de Fabric\n",
    "\n",
    "Debemos escoger la capacidad que vamos a utilizar para asignarla al o las áreas de trabajo que se crearán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320fafce-01c2-42d3-8892-83b4f5361422",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": "2025-04-06T13:53:25.4799259Z",
       "livy_statement_state": "running",
       "normalized_state": "running",
       "parent_msg_id": "422bf203-eea1-4b73-8ea7-b55cb7962f4d",
       "queued_time": "2025-04-06T13:53:17.3982111Z",
       "session_id": "53be198c-a29e-4e26-a4ef-280d4d527fc2",
       "session_start_time": null,
       "spark_pool": null,
       "state": "submitted",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": [
       "StatementMeta(, 53be198c-a29e-4e26-a4ef-280d4d527fc2, 4, Submitted, Running, Running)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fabric.list_capacities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52108fe-169f-46bb-9670-d3b76703a239",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-06T13:45:26.0096114Z",
       "execution_start_time": "2025-04-06T13:45:25.0453292Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7875a4f3-f677-468a-a27b-859cd2611d5c",
       "queued_time": "2025-04-06T13:45:25.044123Z",
       "session_id": "5d838bba-75f7-4d58-9984-610f2c105db1",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 31,
       "statement_ids": [
        31
       ]
      },
      "text/plain": [
       "StatementMeta(, 5d838bba-75f7-4d58-9984-610f2c105db1, 31, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projectName:str = \"ProjectName\"\n",
    "layers:list[str] = [\"01_BRONZE\",\"02_SILVER\",\"03_GOLD\"]\n",
    "capacityId:str = \"CapacityId\"\n",
    "medallionInOneWorkspace:bool = False\n",
    "\n",
    "azureKeyVault:bool = True\n",
    "azureKeyVaultName:str = \"azure-key-vault-name\"\n",
    "SUBSCRIPTION_ID:str = mssparkutils.credentials.getSecret(f'https://{azureKeyVaultName}.vault.azure.net/', '')\n",
    "TENANT_ID:str = mssparkutils.credentials.getSecret(f'https://{azureKeyVaultName}.vault.azure.net/', '')\n",
    "CLIENT_ID:str = mssparkutils.credentials.getSecret(f'https://{azureKeyVaultName}.vault.azure.net/', '')\n",
    "CLIENT_SECRET:str = mssparkutils.credentials.getSecret(f'https://{azureKeyVaultName}.vault.azure.net/', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d20fe-2d9e-4e09-9cd8-fc9b0c86c45c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Comprobación de variables obligatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70e41528-e10b-42d1-88d0-ed94be6292fe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-06T13:44:52.5706496Z",
       "execution_start_time": "2025-04-06T13:44:52.2246475Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "23138bd3-7cf8-43b6-b88b-fbe18fb794ef",
       "queued_time": "2025-04-06T13:44:46.292294Z",
       "session_id": "5d838bba-75f7-4d58-9984-610f2c105db1",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 28,
       "statement_ids": [
        28
       ]
      },
      "text/plain": [
       "StatementMeta(, 5d838bba-75f7-4d58-9984-610f2c105db1, 28, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuración validada correctamente.\n"
     ]
    }
   ],
   "source": [
    "def is_null_or_empty(value):\n",
    "    return value is None or (isinstance(value, str) and value.strip() == \"\") or (isinstance(value, list) and len(value) == 0)\n",
    "\n",
    "def validar_configuracion_global():\n",
    "    errores = []\n",
    "\n",
    "    # Validación general del proyecto\n",
    "    if is_null_or_empty(projectName):\n",
    "        errores.append(\" - 'projectName' no está definido o está vacío.\")\n",
    "    if is_null_or_empty(layers):\n",
    "        errores.append(\" - 'layers' no está definido o la lista está vacía.\")\n",
    "    if is_null_or_empty(capacityId):\n",
    "        errores.append(\" - 'capacityId' no está definido o está vacío.\")\n",
    "\n",
    "    # Validación de Azure Key Vault si está habilitado\n",
    "    if azureKeyVault:\n",
    "        if is_null_or_empty(azureKeyVaultName):\n",
    "            errores.append(\" - 'azureKeyVaultName' no está definido o está vacío.\")\n",
    "        if is_null_or_empty(SUBSCRIPTION_ID):\n",
    "            errores.append(\" - 'SUBSCRIPTION_ID' no está definido o está vacío.\")\n",
    "        if is_null_or_empty(TENANT_ID):\n",
    "            errores.append(\" - 'TENANT_ID' no está definido o está vacío.\")\n",
    "        if is_null_or_empty(CLIENT_ID):\n",
    "            errores.append(\" - 'CLIENT_ID' no está definido o está vacío.\")\n",
    "        if is_null_or_empty(CLIENT_SECRET):\n",
    "            errores.append(\" - 'CLIENT_SECRET' no está definido o está vacío.\")\n",
    "\n",
    "    # Mostrar errores y detener ejecución si los hay\n",
    "    if errores:\n",
    "        print(\"❌ Se encontraron los siguientes problemas de configuración:\")\n",
    "        for error in errores:\n",
    "            print(error)\n",
    "        notebookutils.session.stop()\n",
    "\n",
    "    print(\"✅ Configuración validada correctamente.\")\n",
    "\n",
    "validar_configuracion_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37eeb9-052a-4987-b5c4-c91bffb9a46f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922592f9-12c5-4331-9bd5-372b4b094398",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-06T13:44:52.9154126Z",
       "execution_start_time": "2025-04-06T13:44:52.5728481Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "6a327935-9798-4d57-a19e-6c57a05b33b1",
       "queued_time": "2025-04-06T13:44:46.3594364Z",
       "session_id": "5d838bba-75f7-4d58-9984-610f2c105db1",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 29,
       "statement_ids": [
        29
       ]
      },
      "text/plain": [
       "StatementMeta(, 5d838bba-75f7-4d58-9984-610f2c105db1, 29, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_workspace(workspace_name:str,capacity_id:str,description:str):\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "\n",
    "    Función para crear un área de trabajo.\n",
    "\n",
    "    Parámetros:\n",
    "    - workspace_name (str): Nombre del área de trabajo a crear.\n",
    "    - capacity_id (str): ID de la capacidad en la que se asignará el área de trabajo.\n",
    "    - description (str): Descripción del área de trabajo.\n",
    "\n",
    "    Devuelve:\n",
    "    - str: ID del área de trabajo creada si la operación es exitosa.\n",
    "    - None: En caso de error.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        workspaceId = fabric.create_workspace(workspace_name, capacity_id, description)\n",
    "        print(f\"✅ Área de trabajo {workspace_name} creada con éxito:\")\n",
    "        print(f\"ℹ️ Workspace ID: {workspaceId}\")\n",
    "        return workspaceId\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"❌ Error al crear el área de trabajo: \", error)\n",
    "        return None\n",
    "\n",
    "\n",
    "def search_workspace(workspace_name: str):\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "\n",
    "    Busca un área de trabajo en Microsoft Fabric por su nombre.\n",
    "\n",
    "    Parámetros:\n",
    "    - workspace_name (str): Nombre del área de trabajo a buscar.\n",
    "\n",
    "    Devuelve:\n",
    "    - pd.DataFrame: Un DataFrame con la información del área de trabajo si existe.\n",
    "    - None: Si ocurre un error o no se encuentra el área de trabajo.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        workspace = fabric.list_workspaces(filter=f\"name eq '{workspace_name}'\")\n",
    "        return workspace\n",
    "    except Exception as error:\n",
    "        print(\"❌ Error al buscar el área de trabajo: \", error)\n",
    "        return None\n",
    "\n",
    "def list_lakehouses(workspace_id:str):\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "\n",
    "    Lista todos los lakehouses disponibles en un área de trabajo en Microsoft Fabric.\n",
    "\n",
    "    Esta función utiliza la API de Microsoft Fabric para obtener una lista de todos los lakehouses\n",
    "    asociados con un área de trabajo específica, identificada por el parámetro `workspace_id`. \n",
    "    Si la operación es exitosa, devuelve una lista con los lakehouses. En caso de que ocurra un \n",
    "    error durante la operación, captura la excepción y muestra un mensaje de error.\n",
    "\n",
    "    Parámetros:\n",
    "    - workspace_id (str): El identificador del área de trabajo en Microsoft Fabric para la cual \n",
    "      se desean obtener los lakehouses.\n",
    "\n",
    "    Devuelve:\n",
    "    - list: Una lista de los lakehouses disponibles en el área de trabajo. Si ocurre un error, \n",
    "      devuelve `None`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        lakehouses = notebookutils.lakehouse.list(workspace_id)\n",
    "        return lakehouses\n",
    "    except Exception as error:\n",
    "        print(\"❌ Error al listar los lakehouses: \", error)\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_lakehouse(lakehouse_name: str, workspace_id: str):\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "    \n",
    "    Crea un nuevo lakehouse en un área de trabajo de Microsoft Fabric.\n",
    "\n",
    "    Esta función interactúa con la API de Microsoft Fabric para crear un nuevo lakehouse\n",
    "    dentro de un área de trabajo específica, identificada por el parámetro `workspace_id`. \n",
    "    El lakehouse se crea con el nombre especificado por el parámetro `lakehouse_name`, \n",
    "    y se pueden personalizar otros parámetros como la descripción y el número máximo de intentos \n",
    "    para la creación. Si la operación es exitosa, se devuelve el id del lakehouse creado. \n",
    "    En caso de error, la función captura la excepción y muestra un mensaje de error en consola.\n",
    "\n",
    "    Parámetros:\n",
    "    - lakehouse_name (str): El nombre que se asignará al nuevo lakehouse.\n",
    "    - workspace_id (str): El identificador del área de trabajo en Microsoft Fabric donde se creará \n",
    "      el lakehouse.\n",
    "\n",
    "    Devuelve:\n",
    "    - str: El ID del lakehouse creado en Microsoft Fabric. Si ocurre un error durante la \n",
    "      creación, devuelve `None`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    description = \"\"\n",
    "    max_attempts = 10\n",
    "\n",
    "    try:\n",
    "        lakehouseId = fabric.create_lakehouse(lakehouse_name, description, max_attempts, workspace_id)\n",
    "        return lakehouseId\n",
    "    except Exception as error:\n",
    "        print(f\"❌ Error al crear el lakehouse {lakehouse_name}: \", error)\n",
    "        return None\n",
    "\n",
    "\n",
    "def azurekeyvault_authentication():\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "\n",
    "    Autentica una aplicación contra Azure Key Vault utilizando MSAL (Microsoft Authentication Library) \n",
    "    con credenciales de cliente.\n",
    "\n",
    "    Parámetros globales esperados:\n",
    "    - TENANT_ID (str): ID del tenant de Azure Active Directory.\n",
    "    - CLIENT_ID (str): ID de la aplicación registrada en Azure AD.\n",
    "    - CLIENT_SECRET (str): Secreto del cliente configurado en la app de Azure AD.\n",
    "\n",
    "    Devuelve:\n",
    "    - str: Token de acceso (access token) válido para acceder a Azure Key Vault.\n",
    "    - None: Si ocurre un error durante la autenticación.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    AUTHORITY = f\"https://login.microsoftonline.com/{TENANT_ID}\"\n",
    "    KV_RESOURCE = \"https://vault.azure.net/\"\n",
    "    SCOPE = KV_RESOURCE + \".default\"\n",
    "\n",
    "    app = msal.ConfidentialClientApplication(CLIENT_ID, authority=AUTHORITY, client_credential=CLIENT_SECRET)\n",
    "    token_response = app.acquire_token_for_client(scopes=[SCOPE])\n",
    "\n",
    "    if \"access_token\" in token_response:\n",
    "        access_token = token_response[\"access_token\"]\n",
    "        print(\"✅ Autenticación exitosa para Key Vault\")\n",
    "        return access_token\n",
    "    else:\n",
    "        print(\"❌ Error en la autenticación:\", token_response)\n",
    "        return None\n",
    "\n",
    "def store_workspace_id_secret(workspace_name: str, workspace_id: str, azure_key_vault_name: str, kv_access_token: str):\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "\n",
    "    Almacena el ID de un Workspace como un secreto en Azure Key Vault.\n",
    "\n",
    "    Parámetros:\n",
    "    - workspace_name (str): Nombre del área de trabajo.\n",
    "    - workspace_id (str): ID del Lakehouse a almacenar como secreto.\n",
    "    - azure_key_vault_name (str): Nombre del Key Vault de Azure.\n",
    "    - kv_access_token (str): Token de acceso para autenticación contra Key Vault.\n",
    "\n",
    "    Devuelve:\n",
    "    - bool: True si el secreto se almacenó correctamente, False en caso contrario.\n",
    "    \"\"\"\n",
    "\n",
    "    secret_name = f\"{workspace_name}-workspace-id\".replace(\"_\", \"-\").lower()\n",
    "    secret_value = workspace_id\n",
    "\n",
    "    secret_url = f\"https://{azure_key_vault_name}.vault.azure.net/secrets/{secret_name}?api-version=7.3\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {kv_access_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\"value\": secret_value}\n",
    "\n",
    "    response = requests.put(secret_url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f\"🔑 Secreto '{secret_name}' almacenado correctamente en {azure_key_vault_name}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ Error al almacenar el secreto '{secret_name}':\", response.text)\n",
    "        return False\n",
    "\n",
    "\n",
    "def store_lakehouse_id_secret(project_name: str, layer: str, lakehouse_id: str, azure_key_vault_name: str, kv_access_token: str):\n",
    "    \"\"\"\n",
    "    Kilian Baccaro | datagym.es\n",
    "\n",
    "    Almacena el ID de un Lakehouse como un secreto en Azure Key Vault.\n",
    "\n",
    "    Parámetros:\n",
    "    - project_name (str): Nombre del proyecto.\n",
    "    - layer (str): Capa del Lakehouse (por ejemplo: 'bronze', 'silver', etc.).\n",
    "    - lakehouse_id (str): ID del Lakehouse a almacenar como secreto.\n",
    "    - azure_key_vault_name (str): Nombre del Key Vault de Azure.\n",
    "    - kv_access_token (str): Token de acceso para autenticación contra Key Vault.\n",
    "\n",
    "    Devuelve:\n",
    "    - bool: True si el secreto se almacenó correctamente, False en caso contrario.\n",
    "    \"\"\"\n",
    "\n",
    "    secret_name = f\"{project_name}-{layer}-lh-id\".replace(\"_\", \"-\").lower()\n",
    "    secret_value = lakehouse_id\n",
    "\n",
    "    secret_url = f\"https://{azure_key_vault_name}.vault.azure.net/secrets/{secret_name}?api-version=7.3\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {kv_access_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\"value\": secret_value}\n",
    "\n",
    "    response = requests.put(secret_url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f\"🔑 Secreto '{secret_name}' almacenado correctamente en {azure_key_vault_name}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ Error al almacenar el secreto '{secret_name}':\", response.text)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0afae3b-184a-4ab2-b5f1-769ce4a3a9a1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c0955-2e52-45a8-a4ce-6b216798733b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-06T13:46:48.816991Z",
       "execution_start_time": "2025-04-06T13:45:29.4351924Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "f1739583-23a1-4816-b22b-3df22d965dd5",
       "queued_time": "2025-04-06T13:45:29.4330736Z",
       "session_id": "5d838bba-75f7-4d58-9984-610f2c105db1",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 32,
       "statement_ids": [
        32
       ]
      },
      "text/plain": [
       "StatementMeta(, 5d838bba-75f7-4d58-9984-610f2c105db1, 32, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Script configurado para almacenar los secretos en Azure Key Vault\n",
      "✅ Autenticación exitosa para Key Vault\n",
      "\n",
      "ℹ️ El script está configurado para crear un área de trabajo para cada capa\n",
      "ℹ️ Inicializando la creación del área de trabajo...\n",
      "ℹ️ Creando área de trabajo DataGym_DEV_01_BRONZE...\n",
      "✅ Área de trabajo DataGym_DEV_01_BRONZE creada con éxito:\n",
      "ℹ️ Workspace ID: 24ef2ff7-b97d-4402-a34e-f34752dfcf92\n",
      "🔑 Secreto 'datagym-dev-01-bronze-workspace-id' almacenado correctamente en kbsfabrickv\n",
      "\n",
      "ℹ️ Inicializando la creación de los lakehouses...\n",
      "ℹ️ Creando lakehouse DataGym_DEV_01_BRONZE_lh...\n",
      "✅ Lakehouse creado con éxito:\n",
      "🔑 Secreto 'datagym-dev-01-bronze-01-bronze-lh-id' almacenado correctamente en kbsfabrickv\n",
      "\n",
      "✅ Ejecución finalizada.\n",
      "ℹ️ Creando área de trabajo DataGym_DEV_02_SILVER...\n",
      "✅ Área de trabajo DataGym_DEV_02_SILVER creada con éxito:\n",
      "ℹ️ Workspace ID: 35d1d7db-8c80-48e0-8255-a6054ec8a397\n",
      "🔑 Secreto 'datagym-dev-02-silver-workspace-id' almacenado correctamente en kbsfabrickv\n",
      "\n",
      "ℹ️ Inicializando la creación de los lakehouses...\n",
      "ℹ️ Creando lakehouse DataGym_DEV_02_SILVER_lh...\n",
      "✅ Lakehouse creado con éxito:\n",
      "🔑 Secreto 'datagym-dev-02-silver-02-silver-lh-id' almacenado correctamente en kbsfabrickv\n",
      "\n",
      "✅ Ejecución finalizada.\n",
      "ℹ️ Creando área de trabajo DataGym_DEV_03_GOLD...\n",
      "✅ Área de trabajo DataGym_DEV_03_GOLD creada con éxito:\n",
      "ℹ️ Workspace ID: 68078abd-edb7-4521-97c2-0824167dc2c0\n",
      "🔑 Secreto 'datagym-dev-03-gold-workspace-id' almacenado correctamente en kbsfabrickv\n",
      "\n",
      "ℹ️ Inicializando la creación de los lakehouses...\n",
      "ℹ️ Creando lakehouse DataGym_DEV_03_GOLD_lh...\n",
      "✅ Lakehouse creado con éxito:\n",
      "🔑 Secreto 'datagym-dev-03-gold-03-gold-lh-id' almacenado correctamente en kbsfabrickv\n",
      "\n",
      "✅ Ejecución finalizada.\n",
      "CPU times: user 1.37 s, sys: 27.6 ms, total: 1.4 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Conexión a Azure Key Vault\n",
    "if azureKeyVault:\n",
    "    print(\"ℹ️ Script configurado para almacenar los secretos en Azure Key Vault\")\n",
    "    kv_access_token = azurekeyvault_authentication()\n",
    "    print(\"\")\n",
    "\n",
    "# Si la variable es True, generamos todo en un área de trabajo\n",
    "if (medallionInOneWorkspace):\n",
    "    \"\"\"\n",
    "    ÁREA DE TRABAJO\n",
    "    \n",
    "    Se comprueba si existe el área de trabajo. Si existe, obtenemos el workspaceId, sino, creamos el área de trabajo y obtenemos el workspaceId.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ℹ️ El script está configurado para crear todo en una área de trabajo\")\n",
    "    print(\"ℹ️ Inicializando la creación del área de trabajo...\")\n",
    "\n",
    "    # Buscamos si ya existe el área de trabajo\n",
    "    workspace = search_workspace(projectName)\n",
    "\n",
    "    if workspace is not None and not workspace.empty:\n",
    "        print(f\"ℹ️ El workspace {projectName} ya existe. Se crearán los objetos sobre esta área de trabajo.\")\n",
    "        print(f\"ℹ️ Workspace ID: {workspace.iloc[0]['Id']}\")\n",
    "        print(f\"ℹ️ Capacity ID: {workspace.iloc[0]['Capacity Id']}\")\n",
    "        workspace_id = workspace.iloc[0]['Id']\n",
    "    else:\n",
    "        print(f\"ℹ️ Creando área de trabajo {projectName}...\")\n",
    "        workspace_id = create_workspace(projectName, capacityId, None)\n",
    "    \n",
    "    if workspace_id is None:\n",
    "        notebookutils.session.stop()\n",
    "\n",
    "    if azureKeyVault and kv_access_token is not None:\n",
    "        store_workspace_id_secret(projectName, workspace_id, azureKeyVaultName, kv_access_token)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    \"\"\"\n",
    "    LAKEHOUSE\n",
    "    \n",
    "    Se crean tantos lakehouse como capas se hayan definido en la variable 'layers' con la nomenclatura (projectName)_(layer)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ℹ️ Inicializando la creación de los lakehouses...\")\n",
    "    lakehousesList = list_lakehouses(workspace_id)\n",
    "\n",
    "    lakehousesExistentes = [\n",
    "        {\"name\": item[\"displayName\"], \"id\": item[\"id\"]}\n",
    "        for item in lakehousesList\n",
    "    ]\n",
    "\n",
    "\n",
    "    for layer in layers:\n",
    "        lakehouseName = f\"{projectName}_{layer}_lh\"\n",
    "\n",
    "        if lakehouseName not in [lh[\"name\"] for lh in lakehousesExistentes]:\n",
    "            print(f\"ℹ️ Creando lakehouse {lakehouseName}...\")\n",
    "            lakehouseId = create_lakehouse(lakehouseName, workspace_id)\n",
    "            if lakehouseId is not None:\n",
    "                print(f\"✅ Lakehouse creado con éxito: {lakehouseId}\")\n",
    "                store_lakehouse_id_secret(projectName, layer, lakehouseId, azureKeyVaultName, kv_access_token)\n",
    "        \n",
    "        else:\n",
    "            print(f\"ℹ️ El lakehouse {lakehouseName} ya existe.\")\n",
    "            for lakehouse in lakehousesExistentes:\n",
    "                if lakehouseName == lakehouse['name']:\n",
    "                    store_lakehouse_id_secret(projectName, layer, lakehouse['id'], azureKeyVaultName, kv_access_token)\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    print(f\"✅ Ejecución finalizada.\")\n",
    "\n",
    "# Si la variable es False, generamos cada capa en un área de trabajo distinta\n",
    "else:\n",
    "    \"\"\"\n",
    "    ÁREA DE TRABAJO\n",
    "    \n",
    "    Se comprueba si existe el área de trabajo. Si existe, obtenemos el workspaceId, sino, creamos el área de trabajo\n",
    "    y obtenemos el workspaceId.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ℹ️ El script está configurado para crear un área de trabajo para cada capa\")\n",
    "    print(\"ℹ️ Inicializando la creación del área de trabajo...\")\n",
    "\n",
    "    workspaces_df = fabric.list_workspaces()\n",
    "    workspacesExistentes = workspaces_df[[\"Name\", \"Id\"]].to_dict(orient=\"records\")\n",
    "\n",
    "    for layer in layers:\n",
    "        workspace_name = f\"{projectName}_{layer}\"\n",
    "        workspace = search_workspace(workspace_name)\n",
    "\n",
    "        if workspace is not None and not workspace.empty:\n",
    "            print(f\"ℹ️ El workspace {workspace_name} ya existe. Se crearán los objetos sobre esta área de trabajo.\")\n",
    "            print(f\"ℹ️ Workspace ID: {workspace.iloc[0]['Id']}\")\n",
    "            print(f\"ℹ️ Capacity ID: {workspace.iloc[0]['Capacity Id']}\")\n",
    "            print(\"\")\n",
    "            workspace_id = workspace.iloc[0]['Id']\n",
    "        else:\n",
    "            print(f\"ℹ️ Creando área de trabajo {workspace_name}...\")\n",
    "            workspace_id = create_workspace(workspace_name, capacityId, None)\n",
    "        \n",
    "        if workspace_id is None:\n",
    "            notebookutils.session.stop()\n",
    "        \n",
    "        if azureKeyVault and kv_access_token is not None:\n",
    "            store_workspace_id_secret(workspace_name, workspace_id, azureKeyVaultName, kv_access_token)\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        \"\"\"\n",
    "        LAKEHOUSE\n",
    "        \n",
    "        Se crea el lakehouse correspondiente de la capa\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        print(\"ℹ️ Inicializando la creación de los lakehouses...\")\n",
    "        lakehousesList = list_lakehouses(workspace_id)\n",
    "\n",
    "        lakehousesExistentes = [\n",
    "            {\"name\": item[\"displayName\"], \"id\": item[\"id\"]}\n",
    "            for item in lakehousesList\n",
    "        ]\n",
    "\n",
    "        lakehouseName = f\"{projectName}_{layer}_lh\"\n",
    "\n",
    "        if lakehouseName not in [lh[\"name\"] for lh in lakehousesExistentes]:\n",
    "            print(f\"ℹ️ Creando lakehouse {lakehouseName}...\")\n",
    "            lakehouseId = create_lakehouse(lakehouseName, workspace_id)\n",
    "            if lakehouseId is not None:\n",
    "                print(f\"✅ Lakehouse creado con éxito:\")\n",
    "                store_lakehouse_id_secret(workspace_name, layer, lakehouseId, azureKeyVaultName, kv_access_token)\n",
    "        \n",
    "        else:\n",
    "            print(f\"ℹ️ El lakehouse {lakehouseName} ya existe.\")\n",
    "            for lakehouse in lakehousesExistentes:\n",
    "                if lakehouseName == lakehouse['name']:\n",
    "                    store_lakehouse_id_secret(projectName, layer, lakehouse['id'], azureKeyVaultName, kv_access_token)\n",
    "        print(\"\")\n",
    "\n",
    "    print(f\"✅ Ejecución finalizada.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
